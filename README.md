# Attention_Seq2seq-Translation

This repo holds the code for the implementation in my FloydHub article on Attention:

[Link to article](https://blog.floydhub.com/attention-mechanism/)

The notebook containing the walkthrough is *main.ipynb*

It can be ran on FloydHub as well with GPUs

[![Run on FloydHub](https://static.floydhub.com/button/button-small.svg)](https://floydhub.com/run?template=https://github.com/gabrielloye/Attention_Seq2seq-Translation)
